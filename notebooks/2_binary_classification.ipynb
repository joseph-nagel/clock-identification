{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLX case study: Binary classification\n",
    "\n",
    "In the second notebook, we develop different approaches for binary image classification. The goal is to distinguish photos with clocks from photos with other objects. Our solutions can be categorized as follows:\n",
    "1. Postprocessing the output of ImageNet-pretrained models in two different ways.\n",
    "2. Transfer learning with pretrained feature extractors and the available OLX data.\n",
    "\n",
    "All models are  in PyTorch. This is an arbitrary choice, since one can very certainly do the same things in Tensorflow for example. During the experiments I did not have access to a GPU. Hence, GPU support is disabled at the moment.\n",
    "\n",
    "We will now start to implement and train the models. Thereafter we will investigate the quality of their binary decisions as well as their confidence scores (if available). The model that performs best in that regards is saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_curve, \n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    DataImport, BinarySet, SummedProbabilities,\n",
    "    BalancedSampler, ClassifierTraining,\n",
    "    analyze_predictions, predict_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import\n",
    "\n",
    "Let us import the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data' # data directory\n",
    "\n",
    "guess_label = lambda file_name:'clock' if '_' not in file_name else 'other' # label from file name\n",
    "\n",
    "data = DataImport(data_dir, guess_label)\n",
    "data.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We then continue with the definition of some small preprocessing pipelines. They determine how the images are processed before being ingested into a model. That might include a normalization/standardization and some resizing or cropping operations. This is a very important step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (224, 224)\n",
    "MEAN = (0.485, 0.456, 0.406) # ImageNet data\n",
    "STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "transform = {\n",
    "    # resized images\n",
    "    'resize': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(SHAPE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD)\n",
    "    ]),\n",
    "    # cropped images\n",
    "    'crop': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.CenterCrop(SHAPE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD)\n",
    "    ]),\n",
    "    # full-sized images\n",
    "    'full': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD)\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_set = BinarySet(data, target='clock', transform=transform['resize'])\n",
    "crop_set = BinarySet(data, target='clock', transform=transform['crop'])\n",
    "full_set = BinarySet(data, target='clock', transform=transform['full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # number of samples per mini-batch\n",
    "\n",
    "resize_loader = DataLoader(resize_set, batch_size=batch_size, shuffle=True)\n",
    "crop_loader = DataLoader(crop_set, batch_size=batch_size, shuffle=True)\n",
    "full_loader = DataLoader(full_set, batch_size=1, shuffle=True) # one image per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can investigate the look of some resized images for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(resize_loader)) # generate data\n",
    "plot_size = (3, 4)\n",
    "plot_ids = np.random.choice(np.arange(len(images)), size=np.prod(plot_size), replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=plot_size[0], ncols=plot_size[1], figsize=(8, 6))\n",
    "for idx, ax in enumerate(axes.ravel().tolist()):\n",
    "    image = np.clip(images[plot_ids[idx]].numpy().transpose(1,2,0) * STD + MEAN, 0, 1)\n",
    "    label = labels[plot_ids[idx]].numpy()\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(label)\n",
    "    ax.set(xticks=[], yticks=[])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained models\n",
    "\n",
    "In the following, we will realize two straightforward ways classifying images with and without clocks. They are based on postprocessing the output of ImageNet-trained models. Among its 1000 standard classes, there are multiple types of watches and clocks. That allows for the two possibilities:\n",
    "- First, one might simply check whether or not a clock-relevant class is contained in the top predictions of the pretrained model.\n",
    "- Second, one could sum up the predicted probabilities for all relevant classes in order to obtain a continuous rather than a binary estimate.\n",
    "\n",
    "To start with, we import a pretrained model. An AlexNet architecture is opted for as the simplest choice. Of course, one might experiment with more complex models as well. That might promise better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = models.alexnet(weights=models.AlexNet_Weights.DEFAULT)\n",
    "# pretrained_model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "# pretrained_model = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False # freeze model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On that basis, a model is constructed that accumulates the probability of being any type of clock. To that end one just has to add the relevant probabilities as predicted by the pretrained model. Unlike in TensorFlow, there is unfortunately no \"decode_predictions\" function in PyTorch. That is why one has to manually select the relevant model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clock_ids = (409, 530, 531, 826, 892) # TODO: check correctness\n",
    "clock_model = SummedProbabilities(pretrained_model, clock_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of first model is now evaluated on the basis of the full-sized images. For a given number of how many predicted top classes should be considered, some measures such as the accuracy and the confusion matrix are computed. While the number of top classes is suprisingly high, the classification performance of this simple approach is \"ok-ish\". A more detailed analysis can be certainly done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 70 # top k classes to include\n",
    "\n",
    "summary = analyze_predictions(\n",
    "    pretrained_model,\n",
    "    full_loader,\n",
    "    k=k,\n",
    "    target_ids=clock_ids\n",
    ")\n",
    "\n",
    "print('Confusion matrix:\\n', summary['confusion'])\n",
    "print('Accuracy: {:.2f}'.format(summary['accuracy']))\n",
    "print('Precision: {:.2f}'.format(summary['precision']))\n",
    "print('Recall: {:.2f}'.format(summary['recall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second model that accumulates the probability of being a clock over all relevant ImageNet classes, the performance evaluation proceeds analogously. A suprisingly low threshold parameter leads to an \"acceptable\" classifier. Its performance on full-sized images is comparable to the first model. We observe similar results when using the resized images with different aspect ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.007 # probability threshold\n",
    "\n",
    "summary = analyze_predictions(\n",
    "    clock_model,\n",
    "    full_loader,\n",
    "    threshold=threshold\n",
    ")\n",
    "\n",
    "print('Confusion matrix:\\n', summary['confusion'])\n",
    "print('Accuracy: {:.2f}'.format(summary['accuracy']))\n",
    "print('Precision: {:.2f}'.format(summary['precision']))\n",
    "print('Recall: {:.2f}'.format(summary['recall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, both approaches provide a viable classifier. The first one makes purely binary decisions, whereas the second one establishes a continuous classification score with a probabilistic interpretation. Due to its small values, however, the use of this score might be arguable. One interpretation is that the clocks and other objects in the OLX data set are somewhat different (but not too much) from images found in ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "An alternative method based on transfer learning is pursued. Here, the same pretrained model is taken as a feature extractor, and a new binary classification head is trained on the basis of our data. This will hopefully yield a well-behaved continuous classification score. On the downside, we do not expect that this would generalize well to data distributions that are very different from our data set.\n",
    "\n",
    "Since our data set is small, we use data augmentation techniques. The first step is to define an appropriate  augmentation pipeline. We simply use some more or less reasonable settings. The parameters should be more carefully tuned in the future though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform['train'] = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(\n",
    "        45, # too (less) agressive?\n",
    "        interpolation=transforms.InterpolationMode.BILINEAR\n",
    "    ),\n",
    "    transforms.RandomResizedCrop(SHAPE),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is also weakly imbalanced. Hence, an oversampling scheme is implemented that generates roughly balanced mini-batches. In conjunction with data augmentation, this mitigates the imbalance to some degree. A split between train and validation set is also realized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_frac = 0.3 # fraction of samples for validation\n",
    "\n",
    "train_set = BinarySet(\n",
    "    data,\n",
    "    target='clock',\n",
    "    transform=transform['train']\n",
    ")\n",
    "\n",
    "indices = np.random.permutation(np.arange(len(train_set)))\n",
    "split_idx = int(np.floor((1 - val_frac) * len(train_set)))\n",
    "train_ids = indices[:split_idx].tolist()\n",
    "val_ids = indices[split_idx:].tolist()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    sampler=BalancedSampler(train_set, indices=train_ids)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    sampler=BalancedSampler(train_set, indices=val_ids)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our binary classification architecture. It mainly consists of a pretrained feature extractor and a linear single-output classifier at the end. It is remarked that the final model output is not yet activated with a sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = nn.Sequential(\n",
    "    pretrained_model.features,\n",
    "    nn.AdaptiveAvgPool2d(output_size=(6, 6)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=256*6*6, out_features=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary cross entropy is used as the loss function and an \"arbitrary\" optimizer and learning rate is chosen. Only the weights of the final classification layer are trained. An l2-regularizer is used on those weights. A systematic hyperparameter optimization is beyond the scope of this case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(reduction='mean') # requires logits\n",
    "\n",
    "optimizer = torch.optim.Adam(binary_model.parameters(), lr=0.001, weight_decay=0.2)\n",
    "\n",
    "classifier = ClassifierTraining(\n",
    "    binary_model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to start the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = classifier.fit(no_epochs=100, log_interval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us shortly have a look at the mandatory standard plot below. Keep in mind that only a single layer has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(np.array(history['train_loss']), label='train', alpha=0.7)\n",
    "ax.plot(np.array(history['val_loss']), label='val.', alpha=0.7)\n",
    "ax.set(xlabel='epoch', ylabel='loss')\n",
    "ax.set_xlim((0, history['no_epochs']))\n",
    "ax.legend()\n",
    "ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracies on the train and val. set are evaluated. We are not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = classifier.test(train_loader)\n",
    "val_loss, val_acc = classifier.test(val_loader)\n",
    "\n",
    "print('Train acc.: {:.4f}'.format(train_acc))\n",
    "print('Val. acc.: {:.4f}'.format(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparing against the non-learning approaches from above, the performance is also evaluated on the set of full-sized images that have not been resized and augmented. Of course one might here criticize the overlap with the training set. The threshold parameter could be further tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5 # probability threshold\n",
    "\n",
    "summary = analyze_predictions(\n",
    "    binary_model,\n",
    "    full_loader,\n",
    "    threshold=threshold\n",
    ")\n",
    "\n",
    "print('Confusion matrix:\\n', summary['confusion'])\n",
    "print('Accuracy: {:.2f}'.format(summary['accuracy']))\n",
    "print('Precision: {:.2f}'.format(summary['precision']))\n",
    "print('Recall: {:.2f}'.format(summary['recall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that looks quite good. The performance is better than the previous approaches. Moreover we have now a meaningful classification score. We export the learned weights, such that they can be imported and used later on. We only have to keep the limitations in mind when deploying the model. For a better model that would generalize beyond our toy scenario, we would need data sets that contain more images and more object categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = '../weights.pt'\n",
    "torch.save(binary_model[-1].state_dict(), weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum: Classifier evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = predict_loader(\n",
    "    binary_model,\n",
    "    full_loader,\n",
    "    return_true=True\n",
    ")\n",
    "y_pred = y_pred.numpy()\n",
    "y_true = y_true.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "print('Area under ROC curve: {:.4f}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "print('Area under PR curve: {:.4f}'.format(auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "axes[0].plot(fpr, tpr)\n",
    "axes[0].set(title='ROC curve', xlabel='FPR', ylabel='TPR')\n",
    "axes[1].plot(recall, precision)\n",
    "axes[1].set(title='PR curve', xlabel='recall', ylabel='precision')\n",
    "for ax in axes:\n",
    "    ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "    ax.set_axisbelow(True)\n",
    "axes[1].yaxis.set_label_position('right')\n",
    "axes[1].yaxis.tick_right()\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
